{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More cool stuff to do with MLFlow\n",
    "\n",
    "## Using python functions with MLFlow\n",
    "MLFlow uses its own knowledge base to know how to wrap ML models developped in Pytorch, Tensorflow, Scikit-learn etc. But sometimes, we don't want to use a model that comes directly from these frameworks. Sometimes, we want to wrap models that are made partially or entirely in Python. Yes Shukri, even you. MLFlow can do that. We will recreate the same model, but this time we will add some python functions to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Data\n",
    "csv_url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    "data = pd.read_csv(csv_url, sep=\";\")\n",
    "train, test = train_test_split(data)\n",
    "train_x = train.drop([\"quality\"], axis=1)\n",
    "test_x = test.drop([\"quality\"], axis=1)\n",
    "train_y = train[[\"quality\"]]\n",
    "test_y = test[[\"quality\"]]\n",
    "# Parameters\n",
    "alpha = 0.5\n",
    "l1_ratio = 0.5\n",
    "# Model (train)\n",
    "with mlflow.start_run():\n",
    "    # Train the model\n",
    "    lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n",
    "    lr.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get some data to test our model, to be sure that it works once wrapped. I have a dataframe serialized in json for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_query = pd.read_json ('test.json', orient='split')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now save our model, in order to be able to open it from another python function. We are simply going to serialize it with pickle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'model.sklrn'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(lr, outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = open(filename, 'rb')\n",
    "model = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.06405619])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_query = pd.read_json ('test.json', orient='split')\n",
    "model.predict(df_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new Python Function that complements our Model\n",
    "Perfect! It works. This time, we saved our model without mlflow. However, we cannot use MLFLow's magic to serve it yet. But remember, we have more things to add to it. We will add a function to our ML pipeline, that will take the output of the ElasticSearch model and return the verbal evaluation of the wine. In order to do so, I created a text file with verbal evaluations and we are going to map wine qualities to these verbal evaluations with our function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 'Rooooh! Very bad!',\n",
       " '2.5': 'Non non non! Not acceptable!',\n",
       " '5.0': 'Mouais, Not bad',\n",
       " '7.5': 'Ah! This is quite tasty!',\n",
       " '10.0': 'Scrogneugneux! Amazing!'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "reaction_file = open('reaction.txt')\n",
    "values = {}\n",
    "count = 0\n",
    "for i in reaction_file.readlines():\n",
    "    values[str(count)] = i.replace('\\n','')\n",
    "    count += 2.5\n",
    "reaction_file.close()\n",
    "\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reaction(quality, values):\n",
    "    index = min(values, key=lambda x:abs(float(x)-quality))\n",
    "    return values[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Non non non! Not acceptable!'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reaction(3.612627480115992, values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap the pipeline\n",
    "Perfect. Now, we will wrap our own pipeline (our two functions) in a bigger function, that will get a wine sample as an input, load the pickled sklearn model, use the imput to predict wine quality (double), and use the new function to give a verbal evaluation (string), then return this evaluation as an output. This time, we will wrap everything with MLFlow in order to serve it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create main class\n",
    "import pickle\n",
    "from mlflow.pyfunc import PythonModel\n",
    "\n",
    "class wine_predict(PythonModel):\n",
    "    \n",
    "    def __init__(self):\n",
    "        None\n",
    "    \n",
    "    def reaction(quality, values):\n",
    "        index = min(values, key=lambda x:abs(float(x)-myNumber))\n",
    "        return values[index]\n",
    "\n",
    "    def predict(self, context, pd_input):\n",
    "        infile = open('model.sklrn','rb') if context is None else open(context.artifacts[\"model\"], 'rb')\n",
    "        reaction_file = open('reaction.txt') if context is None else open(context.artifacts[\"reaction\"])\n",
    "        # Load model\n",
    "        model = pickle.load(infile)\n",
    "        infile.close()\n",
    "        # Load reactions\n",
    "        values = {}\n",
    "        count = 0\n",
    "        for i in reaction_file.readlines():\n",
    "            values[str(count)] = i.replace('\\n','')\n",
    "            count += 2.5\n",
    "        reaction_file.close()\n",
    "        # Get score\n",
    "        quality = model.predict(pd_input)\n",
    "        # Get value\n",
    "        return reaction(quality, values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the whole pipeline..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mouais, Not bad'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = wine_predict()\n",
    "test.predict(None, df_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use artifacts and generate Conda environments\n",
    "Remember how we had to create a yaml file with the conda environment? We can do it from the code, creating it as a dictionnary as a parameter. We will do this now to simplify the deployment. The second thing that we need to do is to handle artifacts. Our code needs the *reaction.txt* file to work properly. This file might not be present in the environment where we serve our model. For this reason, we will need to specify it as a needed artefact with MLFlow. The same reasoning applies to our piclked model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import os\n",
    "## Create the conda environment of our mlflow (python and pathos for model serving)\n",
    "conda_env = {\n",
    "    'name': 'mlflow-env',\n",
    "    'channels': ['defaults'],\n",
    "    'dependencies': [\n",
    "        'python=3.8',\n",
    "        'numpy',\n",
    "        'pandas',\n",
    "        'scikit-learn',\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Specify the artifacts of our model (the database and the saved minhash model)\n",
    "artifacts = {\n",
    "    \"model\": 'model.sklrn',\n",
    "    \"reaction\": 'reaction.txt'\n",
    "}\n",
    "\n",
    "## Remove previously saved models\n",
    "os.system('rm -r my_model')\n",
    "\n",
    "## Save the model\n",
    "mlflow.pyfunc.save_model(\"my_model\", python_model=test, artifacts=artifacts, conda_env=conda_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test new Model\n",
    "The model has been saved with its artifacts and conda environment. This model is a mixt of python code and Scikit-learn models. We will test it as we tested our purely scikit-learn model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'192.168.0.115'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import socket\n",
    "ip = socket.gethostbyname(socket.gethostname())\n",
    "ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mlflow models serve -m my_model -h 192.168.0.115 -p 1234'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "command = 'mlflow models serve -m my_model -h '+ip+' -p 1234'\n",
    "command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_ip = '94.155.120.231'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curl -X POST -H \"Content-Type:application/json; format=pandas-split\" --data '{\"columns\":[\"alcohol\", \"chlorides\", \"citric acid\", \"density\", \"fixed acidity\", \"free sulfur dioxide\", \"pH\", \"residual sugar\", \"sulphates\", \"total sulfur dioxide\", \"volatile acidity\"],\"data\":[[12.8, 0.029, 0.48, 0.98, 6.2, 29, 3.33, 1.2, 0.39, 75, 0.66]]}' http://94.155.120.231:1234/invocations\n"
     ]
    }
   ],
   "source": [
    "query = '''curl -X POST -H \"Content-Type:application/json; format=pandas-split\" --data '{\"columns\":[\"alcohol\", \"chlorides\", \"citric acid\", \"density\", \"fixed acidity\", \"free sulfur dioxide\", \"pH\", \"residual sugar\", \"sulphates\", \"total sulfur dioxide\", \"volatile acidity\"],\"data\":[[12.8, 0.029, 0.48, 0.98, 6.2, 29, 3.33, 1.2, 0.39, 75, 0.66]]}' http://'''+external_ip+''':1234/invocations'''\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
